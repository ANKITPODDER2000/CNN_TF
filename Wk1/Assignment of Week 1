Congratulations! You passed!
TO PASS 80% or higher
GRADE
100%
Week 1 Quiz
LATEST SUBMISSION GRADE
100%


1.Question 1
What does flow_from_directory give you on the ImageGenerator?


The ability to easily load images for training


The ability to pick the size of training images


The ability to automatically label images based on their directory name


======>>>>All of the above(ANS)

Correct
1 / 1 point


2.Question 2
If my Image is sized 150x150, and I pass a 3x3 Convolution over it, what size is the resulting image?


153x153


450x450


======>>>>148x148


150x150

Correct
1 / 1 point
3.Question 3
If my data is sized 150x150, and I use Pooling of size 2x2, what size will the resulting image be?


300x300


149x149


======>>>>75x75


148x148

Correct
1 / 1 point


4.Question 4
If I want to view the history of my training, how can I access it?


Use a model.fit_generator


Pass the parameter ‘history=true’ to the model.fit


======>>>>Create a variable ‘history’ and assign it to the return of model.fit or model.fit_generator


Download the model and inspect it

Correct
1 / 1 point


5.Question 5
What’s the name of the API that allows you to inspect the impact of convolutions on the images?


The model.images API


======>>>>The model.layers API


The model.pools API


The model.convolutions API

Correct
1 / 1 point


6.Question 6
When exploring the graphs, the loss levelled out at about .75 after 2 epochs, but the accuracy climbed close to 1.0 after 15 epochs. What's the significance of this?


There was no point training after 2 epochs, as we overfit to the validation data


======>>>>There was no point training after 2 epochs, as we overfit to the training data


A bigger training set would give us better validation accuracy


A bigger validation set would give us better training accuracy

Correct
1 / 1 point


7.Question 7
Why is the validation accuracy a better indicator of model performance than training accuracy?


It isn't, they're equally valuable


There's no relationship between them


======>>>>The validation accuracy is based on images that the model hasn't been trained with, and thus a better indicator of how the model will perform with new images.


The validation dataset is smaller, and thus less accurate at measuring accuracy, so its performance isn't as important

Correct
1 / 1 point


8.Question 8
Why is overfitting more likely to occur on smaller datasets?


Because in a smaller dataset, your validation data is more likely to look like your training data


Because there isn't enough data to activate all the convolutions or neurons


Because with less data, the training will take place more quickly, and some features may be missed


======>>>>Because there's less likelihood of all possible features being encountered in the training process.

Correct
